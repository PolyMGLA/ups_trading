{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from utils.windowed_learning_pipeline import Windowed_learning_pipeline\n",
    "from parsers.findata_parsers.binance.parsing_functions import scale, neutralize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "mm = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tima/ups_trading/src/learning_lib\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "pipeline = Windowed_learning_pipeline(\n",
    "    _pth = \"../data/\",\n",
    "    _train_size = 300000,\n",
    "    _dropout_size = 2000,\n",
    "    _win_size = 20000,\n",
    "    _win_train_size = 15000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, h0=None, c0=None):\n",
    "        # If hidden and cell states are not provided, initialize them as zeros\n",
    "        if h0 is None or c0 is None:\n",
    "            print(x)\n",
    "            h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(x.device)\n",
    "            c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(x.device)\n",
    "        \n",
    "        # Forward pass through LSTM\n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])  # Selecting the last output\n",
    "        return out, hn, cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMModel(input_dim=1080, hidden_dim=19, layer_dim=1, output_dim=1080)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 100\n",
    "h0, c0 = None, None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset: np.ndarray, lookback: int, predict_size: int):\n",
    "    \"\"\"принимает numpy-array и превращает его в датасет для обучения LSTM\n",
    "    \n",
    "    Args:\n",
    "        dataset: нампай массив с данными для обучения\n",
    "        lookback: размер исторических данных для предсказания\n",
    "        predict_size: сколько значений вперёд предсказываем\n",
    "\n",
    "    Returns:\n",
    "        X, y: np.ndarray где X - входные данные, y - целевые\n",
    "\n",
    "    \"\"\"\n",
    "    X, y = [], [] #создадим массивы входных и целевых данных\n",
    "    i = 0\n",
    "    while True: #Нарежем\n",
    "        if i + lookback + predict_size > len(dataset):\n",
    "            break\n",
    "        feature = dataset[i:i + lookback]\n",
    "        target = dataset[i + lookback:i + lookback + predict_size]\n",
    "        X.append(feature)\n",
    "        y.append(target)\n",
    "        i += lookback\n",
    "    return torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:27<00:00, 739.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first iteration OK\n",
      "(20000, 1080)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "subtract() got an unexpected keyword argument 'axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m train, test \u001b[38;5;241m=\u001b[39m window\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(train\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m----> 6\u001b[0m train \u001b[38;5;241m=\u001b[39m scale(\u001b[43mneutralize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      7\u001b[0m test \u001b[38;5;241m=\u001b[39m scale(neutralize(test\u001b[38;5;241m.\u001b[39mto_numpy()))\n\u001b[1;32m      8\u001b[0m trainX, trainY \u001b[38;5;241m=\u001b[39m create_dataset(train, \u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m19\u001b[39m)\n",
      "File \u001b[0;32m~/ups_trading/src/learning_lib/parsers/binance_parsing_functions.py:97\u001b[0m, in \u001b[0;36mneutralize\u001b[0;34m(alpha)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mneutralize\u001b[39m(alpha):\n\u001b[0;32m---> 97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubtract\u001b[49m\u001b[43m(\u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: subtract() got an unexpected keyword argument 'axis'"
     ]
    }
   ],
   "source": [
    "window = pipeline.get_nxt()\n",
    "\n",
    "while window is not None:\n",
    "    train, test = window\n",
    "    print(train.shape)\n",
    "    train = scale(neutralize(train.to_numpy()))\n",
    "    test = scale(neutralize(test.to_numpy()))\n",
    "    trainX, trainY = create_dataset(train, 1000, 19)\n",
    "    # print(trainX)\n",
    "    print(trainX.shape) # torch.Size([19, 1000, 1080])\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs, h0, c0 = model(trainX, h0, c0)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, trainY)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Detach hidden and cell states to prevent backpropagation through the entire sequence\n",
    "        h0 = h0.detach()\n",
    "        c0 = c0.detach()\n",
    "\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    window = pipeline.get_nxt()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
